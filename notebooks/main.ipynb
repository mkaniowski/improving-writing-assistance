{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T20:56:15.065868Z",
     "start_time": "2024-11-04T20:56:13.481367Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ],
   "id": "e7176c941fb870b6",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Preparing data",
   "id": "f1147eb1229cbe67"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-04T20:56:15.159370Z",
     "start_time": "2024-11-04T20:56:15.100370Z"
    }
   },
   "source": [
    "from src.read_file_to_df import read_file_to_df\n",
    "\n",
    "df1 = read_file_to_df('../data/spell-testset1.txt')\n",
    "df2 = read_file_to_df('../data/spell-testset2.txt')\n",
    "\n",
    "# ===== Misleading incorrect string ===== #\n",
    "df3 = read_file_to_df('../data/aspell.txt')\n",
    "df4 = read_file_to_df('../data/birkbeck.txt')\n",
    "df5 = read_file_to_df('../data/wikipedia.txt')"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T20:56:15.190369Z",
     "start_time": "2024-11-04T20:56:15.184869Z"
    }
   },
   "cell_type": "code",
   "source": "df_combined = pd.concat([df1, df2], axis=0, ignore_index=True)",
   "id": "58eb4ff55375db12",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T20:56:15.229869Z",
     "start_time": "2024-11-04T20:56:15.218369Z"
    }
   },
   "cell_type": "code",
   "source": "df_combined.to_csv('../data/combined.csv', index=False)",
   "id": "e545134401cc0de7",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T20:56:15.274371Z",
     "start_time": "2024-11-04T20:56:15.265369Z"
    }
   },
   "cell_type": "code",
   "source": "df_combined = pd.read_csv('../data/combined.csv')",
   "id": "5d327f59646b7da8",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T20:56:15.307869Z",
     "start_time": "2024-11-04T20:56:15.301868Z"
    }
   },
   "cell_type": "code",
   "source": "df_sampled = df_combined.sample(n=100, random_state=42)",
   "id": "f087d1a4ba41849e",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "[PySpellChecker](https://pypi.org/project/pyspellchecker/ - Levenshtein distance",
   "id": "9395e580ad6e9fa8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T20:56:29.047370Z",
     "start_time": "2024-11-04T20:56:15.334869Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from spellchecker import SpellChecker\n",
    "from tqdm import tqdm\n",
    "\n",
    "spell = SpellChecker()\n",
    "\n",
    "def get_correction(word):\n",
    "    misspelled = spell.unknown([word])\n",
    "    if misspelled:\n",
    "        correction = spell.correction(word)\n",
    "        if correction:\n",
    "            return correction\n",
    "        else:\n",
    "            return \"incorrectWord\"\n",
    "    return word\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "df_sampled['py_spell_checker'] = df_sampled['incorrect'].progress_apply(get_correction)"
   ],
   "id": "28425478f957812d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001B[A\n",
      "  2%|▏         | 2/100 [00:01<01:05,  1.49it/s]\u001B[A\n",
      " 10%|█         | 10/100 [00:01<00:14,  6.02it/s]\u001B[A\n",
      " 14%|█▍        | 14/100 [00:02<00:15,  5.60it/s]\u001B[A\n",
      " 18%|█▊        | 18/100 [00:03<00:16,  5.09it/s]\u001B[A\n",
      " 19%|█▉        | 19/100 [00:05<00:27,  2.97it/s]\u001B[A\n",
      " 20%|██        | 20/100 [00:06<00:35,  2.28it/s]\u001B[A\n",
      " 37%|███▋      | 37/100 [00:07<00:08,  7.19it/s]\u001B[A\n",
      " 39%|███▉      | 39/100 [00:08<00:11,  5.53it/s]\u001B[A\n",
      " 53%|█████▎    | 53/100 [00:08<00:04,  9.59it/s]\u001B[A\n",
      " 59%|█████▉    | 59/100 [00:09<00:04,  9.04it/s]\u001B[A\n",
      " 62%|██████▏   | 62/100 [00:09<00:04,  7.97it/s]\u001B[A\n",
      " 69%|██████▉   | 69/100 [00:10<00:04,  7.62it/s]\u001B[A\n",
      " 80%|████████  | 80/100 [00:11<00:02,  9.68it/s]\u001B[A\n",
      " 82%|████████▏ | 82/100 [00:12<00:02,  8.21it/s]\u001B[A\n",
      " 87%|████████▋ | 87/100 [00:13<00:01,  7.79it/s]\u001B[A\n",
      "100%|██████████| 100/100 [00:13<00:00,  7.41it/s][A\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T20:56:29.100367Z",
     "start_time": "2024-11-04T20:56:29.094867Z"
    }
   },
   "cell_type": "code",
   "source": [
    "y_true = df_sampled['correct']\n",
    "y_pred = df_sampled['py_spell_checker']"
   ],
   "id": "e3170a150650e44c",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T20:56:29.192868Z",
     "start_time": "2024-11-04T20:56:29.165868Z"
    }
   },
   "cell_type": "code",
   "source": [
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "recall = recall_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "f1 = f1_score(y_true, y_pred, average='macro')"
   ],
   "id": "dbef527b60de9be2",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T20:56:29.243873Z",
     "start_time": "2024-11-04T20:56:29.237370Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 Score: {f1}')"
   ],
   "id": "3825cc43eb18cf2f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.73\n",
      "Precision: 0.5855855855855856\n",
      "Recall: 0.5780780780780781\n",
      "F1 Score: 0.5807807807807808\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T20:56:29.270367Z",
     "start_time": "2024-11-04T20:56:29.264366Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open('../data/py_spellchecker_metrics.txt', 'w') as f:\n",
    "    f.write(f'Accuracy: {accuracy}\\n')\n",
    "    f.write(f'Precision: {precision}\\n')\n",
    "    f.write(f'Recall: {recall}\\n')\n",
    "    f.write(f'F1 Score: {f1}\\n')"
   ],
   "id": "b5476d34e1b68101",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "[Bhuvana/t5-base-spellchecker](https://huggingface.co/Bhuvana/t5-base-spellchecker)",
   "id": "5f149876832fb7c0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T20:56:30.496869Z",
     "start_time": "2024-11-04T20:56:29.295369Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"Bhuvana/t5-base-spellchecker\")\n",
    "\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"Bhuvana/t5-base-spellchecker\")"
   ],
   "id": "9ef17e7b93a78c9a",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T20:56:30.548367Z",
     "start_time": "2024-11-04T20:56:30.543369Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def correct(inputs):\n",
    "    input_ids = tokenizer.encode(inputs,return_tensors='pt')\n",
    "    sample_output = model.generate(\n",
    "        input_ids,\n",
    "        do_sample=True,\n",
    "        max_length=50,\n",
    "        top_p=0.99,\n",
    "        num_return_sequences=1\n",
    "    )\n",
    "    res = tokenizer.decode(sample_output[0], skip_special_tokens=True)\n",
    "    return res"
   ],
   "id": "a9659996aeb65ea0",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T20:57:06.184868Z",
     "start_time": "2024-11-04T20:56:30.601870Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tqdm.pandas()\n",
    "\n",
    "df_sampled['base_spellchecker'] = df_sampled['incorrect'].progress_apply(correct)"
   ],
   "id": "552e8ad8804be3cc",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001B[A\n",
      "  2%|▏         | 2/100 [00:01<01:10,  1.39it/s]\u001B[A\n",
      "  3%|▎         | 3/100 [00:01<00:56,  1.72it/s]\u001B[A\n",
      "  4%|▍         | 4/100 [00:02<00:49,  1.95it/s]\u001B[A\n",
      "  5%|▌         | 5/100 [00:02<00:48,  1.98it/s]\u001B[A\n",
      "  6%|▌         | 6/100 [00:03<00:50,  1.87it/s]\u001B[A\n",
      "  7%|▋         | 7/100 [00:03<00:44,  2.08it/s]\u001B[A\n",
      "  8%|▊         | 8/100 [00:04<00:40,  2.24it/s]\u001B[A\n",
      "  9%|▉         | 9/100 [00:04<00:42,  2.13it/s]\u001B[A\n",
      " 10%|█         | 10/100 [00:04<00:39,  2.27it/s]\u001B[A\n",
      " 11%|█         | 11/100 [00:05<00:36,  2.43it/s]\u001B[A\n",
      " 12%|█▏        | 12/100 [00:05<00:34,  2.52it/s]\u001B[A\n",
      " 13%|█▎        | 13/100 [00:06<00:43,  2.02it/s]\u001B[A\n",
      " 14%|█▍        | 14/100 [00:06<00:37,  2.30it/s]\u001B[A\n",
      " 15%|█▌        | 15/100 [00:07<00:37,  2.25it/s]\u001B[A\n",
      " 16%|█▌        | 16/100 [00:07<00:33,  2.54it/s]\u001B[A\n",
      " 17%|█▋        | 17/100 [00:07<00:29,  2.78it/s]\u001B[A\n",
      " 18%|█▊        | 18/100 [00:08<00:37,  2.19it/s]\u001B[A\n",
      " 19%|█▉        | 19/100 [00:08<00:39,  2.04it/s]\u001B[A\n",
      " 20%|██        | 20/100 [00:09<00:37,  2.14it/s]\u001B[A\n",
      " 21%|██        | 21/100 [00:09<00:38,  2.03it/s]\u001B[A\n",
      " 22%|██▏       | 22/100 [00:10<00:34,  2.29it/s]\u001B[A\n",
      " 23%|██▎       | 23/100 [00:10<00:36,  2.08it/s]\u001B[A\n",
      " 24%|██▍       | 24/100 [00:11<00:31,  2.45it/s]\u001B[A\n",
      " 25%|██▌       | 25/100 [00:11<00:27,  2.69it/s]\u001B[A\n",
      " 26%|██▌       | 26/100 [00:11<00:27,  2.66it/s]\u001B[A\n",
      " 27%|██▋       | 27/100 [00:11<00:24,  2.92it/s]\u001B[A\n",
      " 28%|██▊       | 28/100 [00:12<00:24,  2.91it/s]\u001B[A\n",
      " 29%|██▉       | 29/100 [00:12<00:22,  3.16it/s]\u001B[A\n",
      " 30%|███       | 30/100 [00:12<00:20,  3.35it/s]\u001B[A\n",
      " 31%|███       | 31/100 [00:13<00:18,  3.78it/s]\u001B[A\n",
      " 32%|███▏      | 32/100 [00:13<00:22,  3.02it/s]\u001B[A\n",
      " 33%|███▎      | 33/100 [00:13<00:23,  2.86it/s]\u001B[A\n",
      " 34%|███▍      | 34/100 [00:14<00:22,  2.99it/s]\u001B[A\n",
      " 35%|███▌      | 35/100 [00:14<00:22,  2.90it/s]\u001B[A\n",
      " 36%|███▌      | 36/100 [00:14<00:21,  3.00it/s]\u001B[A\n",
      " 37%|███▋      | 37/100 [00:15<00:21,  2.93it/s]\u001B[A\n",
      " 38%|███▊      | 38/100 [00:15<00:20,  2.99it/s]\u001B[A\n",
      " 39%|███▉      | 39/100 [00:15<00:19,  3.19it/s]\u001B[A\n",
      " 40%|████      | 40/100 [00:16<00:21,  2.82it/s]\u001B[A\n",
      " 41%|████      | 41/100 [00:16<00:21,  2.76it/s]\u001B[A\n",
      " 42%|████▏     | 42/100 [00:16<00:20,  2.85it/s]\u001B[A\n",
      " 43%|████▎     | 43/100 [00:17<00:19,  2.98it/s]\u001B[A\n",
      " 44%|████▍     | 44/100 [00:17<00:21,  2.55it/s]\u001B[A\n",
      " 45%|████▌     | 45/100 [00:18<00:22,  2.50it/s]\u001B[A\n",
      " 46%|████▌     | 46/100 [00:18<00:19,  2.78it/s]\u001B[A\n",
      " 47%|████▋     | 47/100 [00:18<00:16,  3.23it/s]\u001B[A\n",
      " 48%|████▊     | 48/100 [00:19<00:17,  3.03it/s]\u001B[A\n",
      " 49%|████▉     | 49/100 [00:19<00:18,  2.68it/s]\u001B[A\n",
      " 50%|█████     | 50/100 [00:19<00:15,  3.15it/s]\u001B[A\n",
      " 51%|█████     | 51/100 [00:20<00:15,  3.19it/s]\u001B[A\n",
      " 52%|█████▏    | 52/100 [00:20<00:14,  3.41it/s]\u001B[A\n",
      " 53%|█████▎    | 53/100 [00:20<00:12,  3.82it/s]\u001B[A\n",
      " 54%|█████▍    | 54/100 [00:20<00:11,  3.96it/s]\u001B[A\n",
      " 55%|█████▌    | 55/100 [00:21<00:15,  2.99it/s]\u001B[A\n",
      " 56%|█████▌    | 56/100 [00:21<00:14,  3.05it/s]\u001B[A\n",
      " 57%|█████▋    | 57/100 [00:21<00:14,  2.99it/s]\u001B[A\n",
      " 58%|█████▊    | 58/100 [00:22<00:13,  3.07it/s]\u001B[A\n",
      " 59%|█████▉    | 59/100 [00:22<00:11,  3.51it/s]\u001B[A\n",
      " 60%|██████    | 60/100 [00:22<00:12,  3.28it/s]\u001B[A\n",
      " 61%|██████    | 61/100 [00:23<00:12,  3.15it/s]\u001B[A\n",
      " 62%|██████▏   | 62/100 [00:23<00:11,  3.24it/s]\u001B[A\n",
      " 63%|██████▎   | 63/100 [00:23<00:11,  3.28it/s]\u001B[A\n",
      " 64%|██████▍   | 64/100 [00:23<00:10,  3.54it/s]\u001B[A\n",
      " 65%|██████▌   | 65/100 [00:24<00:08,  3.92it/s]\u001B[A\n",
      " 66%|██████▌   | 66/100 [00:24<00:09,  3.47it/s]\u001B[A\n",
      " 67%|██████▋   | 67/100 [00:24<00:11,  2.77it/s]\u001B[A\n",
      " 68%|██████▊   | 68/100 [00:25<00:11,  2.79it/s]\u001B[A\n",
      " 69%|██████▉   | 69/100 [00:25<00:10,  2.89it/s]\u001B[A\n",
      " 70%|███████   | 70/100 [00:25<00:09,  3.00it/s]\u001B[A\n",
      " 71%|███████   | 71/100 [00:26<00:08,  3.30it/s]\u001B[A\n",
      " 72%|███████▏  | 72/100 [00:26<00:08,  3.14it/s]\u001B[A\n",
      " 73%|███████▎  | 73/100 [00:26<00:09,  2.88it/s]\u001B[A\n",
      " 74%|███████▍  | 74/100 [00:27<00:08,  3.20it/s]\u001B[A\n",
      " 75%|███████▌  | 75/100 [00:27<00:06,  3.59it/s]\u001B[A\n",
      " 76%|███████▌  | 76/100 [00:27<00:06,  3.52it/s]\u001B[A\n",
      " 77%|███████▋  | 77/100 [00:28<00:07,  2.92it/s]\u001B[A\n",
      " 78%|███████▊  | 78/100 [00:28<00:07,  2.91it/s]\u001B[A\n",
      " 79%|███████▉  | 79/100 [00:28<00:07,  2.86it/s]\u001B[A\n",
      " 80%|████████  | 80/100 [00:29<00:06,  2.95it/s]\u001B[A\n",
      " 81%|████████  | 81/100 [00:29<00:06,  3.06it/s]\u001B[A\n",
      " 82%|████████▏ | 82/100 [00:29<00:05,  3.28it/s]\u001B[A\n",
      " 83%|████████▎ | 83/100 [00:30<00:06,  2.79it/s]\u001B[A\n",
      " 84%|████████▍ | 84/100 [00:30<00:05,  3.04it/s]\u001B[A\n",
      " 85%|████████▌ | 85/100 [00:30<00:04,  3.15it/s]\u001B[A\n",
      " 86%|████████▌ | 86/100 [00:31<00:04,  3.20it/s]\u001B[A\n",
      " 87%|████████▋ | 87/100 [00:31<00:04,  2.75it/s]\u001B[A\n",
      " 88%|████████▊ | 88/100 [00:31<00:04,  2.92it/s]\u001B[A\n",
      " 89%|████████▉ | 89/100 [00:32<00:03,  3.17it/s]\u001B[A\n",
      " 90%|█████████ | 90/100 [00:32<00:03,  3.26it/s]\u001B[A\n",
      " 91%|█████████ | 91/100 [00:32<00:02,  3.29it/s]\u001B[A\n",
      " 92%|█████████▏| 92/100 [00:33<00:02,  3.16it/s]\u001B[A\n",
      " 93%|█████████▎| 93/100 [00:33<00:02,  3.43it/s]\u001B[A\n",
      " 94%|█████████▍| 94/100 [00:33<00:01,  3.65it/s]\u001B[A\n",
      " 95%|█████████▌| 95/100 [00:33<00:01,  3.79it/s]\u001B[A\n",
      " 96%|█████████▌| 96/100 [00:34<00:01,  3.59it/s]\u001B[A\n",
      " 97%|█████████▋| 97/100 [00:34<00:01,  3.00it/s]\u001B[A\n",
      " 98%|█████████▊| 98/100 [00:34<00:00,  2.93it/s]\u001B[A\n",
      " 99%|█████████▉| 99/100 [00:35<00:00,  3.20it/s]\u001B[A\n",
      "100%|██████████| 100/100 [00:35<00:00,  2.81it/s]\u001B[A\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T20:57:53.085787Z",
     "start_time": "2024-11-04T20:57:53.081286Z"
    }
   },
   "cell_type": "code",
   "source": [
    "y_true = df_sampled['correct']\n",
    "y_pred = df_sampled['base_spellchecker']"
   ],
   "id": "2fd6fe7e06d901b8",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T20:57:53.625783Z",
     "start_time": "2024-11-04T20:57:53.608284Z"
    }
   },
   "cell_type": "code",
   "source": [
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "recall = recall_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "f1 = f1_score(y_true, y_pred, average='macro')"
   ],
   "id": "380c493c074631bc",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T20:57:54.129286Z",
     "start_time": "2024-11-04T20:57:54.122787Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open('../data/base_spellchecker_metrics.txt', 'w') as f:\n",
    "    f.write(f'Accuracy: {accuracy}\\n')\n",
    "    f.write(f'Precision: {precision}\\n')\n",
    "    f.write(f'Recall: {recall}\\n')\n",
    "    f.write(f'F1 Score: {f1}\\n')"
   ],
   "id": "ddd73deaff18fe6e",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T20:59:37.251086Z",
     "start_time": "2024-11-04T20:59:37.245085Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load metrics and comapre them in dataframe\n",
    "with open('../data/py_spellchecker_metrics.txt', 'r') as f:\n",
    "    py_spellchecker_metrics = f.readlines()\n",
    "    \n",
    "with open('../data/base_spellchecker_metrics.txt', 'r') as f:\n",
    "    base_spellchecker_metrics = f.readlines()\n",
    "    \n",
    "py_spellchecker_metrics = [metric.strip() for metric in py_spellchecker_metrics]\n",
    "base_spellchecker_metrics = [metric.strip() for metric in base_spellchecker_metrics]\n",
    "\n",
    "df_metrics = pd.DataFrame({\n",
    "    'py_spellchecker': py_spellchecker_metrics,\n",
    "    'base_spellchecker': base_spellchecker_metrics\n",
    "})"
   ],
   "id": "670cb5c3b1a4f30c",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "c76a0bd5ef198a7d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T20:59:39.086259Z",
     "start_time": "2024-11-04T20:59:39.076760Z"
    }
   },
   "cell_type": "code",
   "source": "df_metrics",
   "id": "307ef7e141c9fe3c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                 py_spellchecker               base_spellchecker\n",
       "0                 Accuracy: 0.73                  Accuracy: 0.09\n",
       "1  Precision: 0.5855855855855856                 Precision: 0.05\n",
       "2     Recall: 0.5780780780780781     Recall: 0.04351851851851852\n",
       "3   F1 Score: 0.5807807807807808  F1 Score: 0.045370370370370366"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>py_spellchecker</th>\n",
       "      <th>base_spellchecker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy: 0.73</td>\n",
       "      <td>Accuracy: 0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Precision: 0.5855855855855856</td>\n",
       "      <td>Precision: 0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Recall: 0.5780780780780781</td>\n",
       "      <td>Recall: 0.04351851851851852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F1 Score: 0.5807807807807808</td>\n",
       "      <td>F1 Score: 0.045370370370370366</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
